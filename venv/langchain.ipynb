{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'%pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!%pip install --upgrade --quiet  langchain-google-genai pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"AIzaSyCJQrqSmM40fsNywHNBIlEoVobOYX35ZMM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 18\n",
      "Found existing installation: langsmith 0.2.4\n",
      "Uninstalling langsmith-0.2.4:\n",
      "  Successfully uninstalled langsmith-0.2.4\n",
      "Found existing installation: langchain 0.3.13\n",
      "Uninstalling langchain-0.3.13:\n",
      "  Successfully uninstalled langchain-0.3.13\n",
      "Found existing installation: langchain-google-genai 2.0.7\n",
      "Uninstalling langchain-google-genai-2.0.7:\n",
      "  Successfully uninstalled langchain-google-genai-2.0.7\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langsmith\n",
      "  Downloading langsmith-0.2.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langchain_google_genai\n",
      "  Downloading langchain_google_genai-2.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.3.27)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.3.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_google_genai) (1.2.0)\n",
      "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_google_genai) (0.8.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.34.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.151.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.35.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (3.20.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.65.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.67.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.48.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.1)\n",
      "Downloading langchain-0.3.13-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.2.4-py3-none-any.whl (320 kB)\n",
      "Downloading langchain_google_genai-2.0.7-py3-none-any.whl (41 kB)\n",
      "Installing collected packages: langsmith, langchain, langchain_google_genai\n",
      "Successfully installed langchain-0.3.13 langchain_google_genai-2.0.7 langsmith-0.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip cache purge\n",
    "!pip uninstall langsmith langchain langchain_google_genai -y\n",
    "!pip install langchain langsmith langchain_google_genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatGoogleGenerativeAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mChatGoogleGenerativeAI\u001b[49m(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-pro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m result \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwho is Lewis Hamilton\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ChatGoogleGenerativeAI' is not defined"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "result = llm.invoke(\"who is Lewis Hamilton\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain==<version> langsmith==<version> langchain_google_genai==<version>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kyoto\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "\n",
    "# Initialize HuggingFaceHub\n",
    "hugging_face_hub = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\", \n",
    "    model_kwargs={\"temperature\": 0, \"max_length\": 64}\n",
    ")\n",
    "output = hugging_face_hub.predict(\"Can you tell me the capital of Japan?\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cricket i 'm a cricketer i 'm a cricketer i 'm a cricketer i 'm a cricketer i 'm a cricketer i 'm a cricketer i 'm a cricket\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "\n",
    "# Initialize HuggingFaceHub\n",
    "hugging_face_hub = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\", \n",
    "    model_kwargs={\"temperature\": 0, \"max_length\": 64}\n",
    ")\n",
    "output = hugging_face_hub.predict(\"generate me a 5 lines of song on cricket \")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20372\\3297772645.py:1: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  output = llm.predict(\"generate me a 5 lines of song on cricket \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the pitch, a battle unfolds,\n",
      "Bat and ball, a tale yet untold.\n",
      "Bowlers spin, fielders dash,\n",
      "As the tension and excitement clash.\n",
      "Cricket's symphony, a thrilling tune,\n",
      "Where skill and strategy intertwine, under the sun.\n"
     ]
    }
   ],
   "source": [
    "output = llm.predict(\"generate me a 5 lines of song on cricket \")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPT TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me the capital of India.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create a prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=['country'],\n",
    "    template=\"Tell me the capital of {country}.\"\n",
    ")\n",
    "\n",
    "# Format the prompt with a specific country\n",
    "formatted_prompt = prompt_template.format(country='India')\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The color of the sun is actually white, but it appears yellow to us because of the way our atmosphere scatters the light.\\n\\nWhen sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen and oxygen. These molecules scatter the shorter, blue wavelengths of light more than the longer, red wavelengths. This is known as Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described the phenomenon in the late 19th century.\\n\\nAs a result of this scattering, the blue light is dispersed in all directions and reaches our eyes from all parts of the sky. The red and yellow light, which is not scattered as much, continues to travel in a more direct path to our eyes, giving the sun its yellowish hue.\\n\\nIf we were to view the sun from space, outside of our atmosphere, it would appear as a brilliant white star, emitting light of all wavelengths equally in all directions. But because of the scattering effect, the sun appears yellow to us on Earth.\\n\\nIt's worth noting that the color of the sun can appear to vary slightly depending on the time of day and the amount of dust and water vapor in the atmosphere. For example, during sunrise and sunset, the sun can take on hues of orange and red due to the increased scattering of light by atmospheric particles. But in general, the sun appears yellow to us because of the scattering of light by our atmosphere.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#while using prompt template we must use chain if we doesnt we get error :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=['country'],\n",
    "    template=\"Tell me the capital of {country}.\"\n",
    ")\n",
    "# Use LLMChain with the initialized model\n",
    "chain = LLMChain(llm=hugging_face_hub, prompt=prompt_template)\n",
    "# Run the chain with input\n",
    "output = chain.run({'country': 'UK'})\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.284)\n",
      "Collecting genai\n",
      "  Downloading genai-2.1.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Collecting langsmith<0.1.0,>=0.0.21 (from langchain)\n",
      "  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.10.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: ipython<9.0.0,>=8.10.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from genai) (8.29.0)\n",
      "Requirement already satisfied: openai<0.28.0,>=0.27.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from genai) (0.27.10)\n",
      "Collecting tabulate<0.10.0,>=0.9.0 (from genai)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tiktoken<0.4.0,>=0.3.2 (from genai)\n",
      "  Downloading tiktoken-0.3.3-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython<9.0.0,>=8.10.0->genai) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython<9.0.0,>=8.10.0->genai) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython<9.0.0,>=8.10.0->genai) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython<9.0.0,>=8.10.0->genai) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython<9.0.0,>=8.10.0->genai) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython<9.0.0,>=8.10.0->genai) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython<9.0.0,>=8.10.0->genai) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython<9.0.0,>=8.10.0->genai) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython<9.0.0,>=8.10.0->genai) (0.4.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<0.28.0,>=0.27.0->genai) (4.64.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken<0.4.0,>=0.3.2->genai) (2024.9.11)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jedi>=0.16->ipython<9.0.0,>=8.10.0->genai) (0.8.4)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (24.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython<9.0.0,>=8.10.0->genai) (0.2.13)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack-data->ipython<9.0.0,>=8.10.0->genai) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack-data->ipython<9.0.0,>=8.10.0->genai) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack-data->ipython<9.0.0,>=8.10.0->genai) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython<9.0.0,>=8.10.0->genai) (1.16.0)\n",
      "Downloading genai-2.1.0-py3-none-any.whl (16 kB)\n",
      "Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tiktoken-0.3.3-cp311-cp311-win_amd64.whl (579 kB)\n",
      "   ---------------------------------------- 0.0/579.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 579.4/579.4 kB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: tabulate, tiktoken, langsmith, genai\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.4.0\n",
      "    Uninstalling tiktoken-0.4.0:\n",
      "      Successfully uninstalled tiktoken-0.4.0\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.147\n",
      "    Uninstalling langsmith-0.1.147:\n",
      "      Successfully uninstalled langsmith-0.1.147\n",
      "Successfully installed genai-2.1.0 langsmith-0.0.92 tabulate-0.9.0 tiktoken-0.3.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-core 0.3.27 requires langsmith<0.3,>=0.1.125, but you have langsmith 0.0.92 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cold\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(\"The opposite of hot is\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTIPLE CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captial_prompt = PromptTemplate(\n",
    "    input_variables=['country'],\n",
    "    template=\"Tell me the capital of {country}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captial_chain = LLMChain(llm= llm ,  prompt=captial_prompt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "captial_prompt = PromptTemplate(\n",
    "    input_variables=['country'],\n",
    "    template=\"Tell me the capital of {country}.\"\n",
    ")\n",
    "captial_chain = LLMChain(llm= llm ,  prompt=captial_prompt )\n",
    "famous_prompt = PromptTemplate(\n",
    "    input_variables=['capital'],\n",
    "    template=\"suggest me some amazing places to visit in {captial}.\"\n",
    ")\n",
    "famous_chain =  LLMChain(llm= llm ,  prompt=famous_prompt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The National Museum of India\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "# Initialize the HuggingFaceHub LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\", \n",
    "    model_kwargs={\"temperature\": 0, \"max_length\": 64}\n",
    ")\n",
    "\n",
    "# Define the prompt template for finding the capital\n",
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"Tell me the capital of {country}.\"\n",
    ")\n",
    "\n",
    "# Create the first chain for finding the capital\n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_prompt)\n",
    "\n",
    "# Define the prompt template for suggesting places\n",
    "famous_prompt = PromptTemplate(\n",
    "    input_variables=[\"capital\"],\n",
    "    template=\"Suggest me some amazing places to visit in {capital}.\"\n",
    ")\n",
    "\n",
    "# Create the second chain for suggesting places\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_prompt)\n",
    "\n",
    "# Combine both chains into a sequential chain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain, famous_chain])\n",
    "\n",
    "# Run the chain with input\n",
    "output = chain.run(\"India\")\n",
    "\n",
    "# Print the output\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Delhi'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "prompt_template = \"Tell me a capital of {country} \"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"], template=prompt_template\n",
    ")\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke(\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_tracing_context' from 'langsmith.run_helpers' (c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langsmith\\run_helpers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain, SimpleSequentialChain\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize the Google Gemini Pro model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatGoogleGenerativeAI(\n\u001b[0;32m      7\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-pro\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# other params...\u001b[39;00m\n\u001b[0;32m     13\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_google_genai\\__init__.py:59\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**LangChain Google Generative AI Integration**\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis module integrates Google's Generative AI models, specifically the Gemini series, with the LangChain framework. It provides classes for interacting with chat models and generating embeddings, leveraging Google's advanced AI capabilities.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HarmBlockThreshold, HarmCategory\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleGenerativeAIEmbeddings\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenai_aqa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     62\u001b[0m     AqaInput,\n\u001b[0;32m     63\u001b[0m     AqaOutput,\n\u001b[0;32m     64\u001b[0m     GenAIAqa,\n\u001b[0;32m     65\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:54\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m caching_types, content_types\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontent_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     FunctionDeclarationType,\n\u001b[0;32m     52\u001b[0m     ToolDict,\n\u001b[0;32m     53\u001b[0m )\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     55\u001b[0m     AsyncCallbackManagerForLLMRun,\n\u001b[0;32m     56\u001b[0m     CallbackManagerForLLMRun,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LanguageModelInput\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseChatModel, LangSmithParams\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\callbacks\\__init__.py:23\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     AsyncCallbackHandler,\n\u001b[0;32m     12\u001b[0m     BaseCallbackHandler,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     ToolManagerMixin,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileCallbackHandler\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     AsyncCallbackManager,\n\u001b[0;32m     25\u001b[0m     AsyncCallbackManagerForChainGroup,\n\u001b[0;32m     26\u001b[0m     AsyncCallbackManagerForChainRun,\n\u001b[0;32m     27\u001b[0m     AsyncCallbackManagerForLLMRun,\n\u001b[0;32m     28\u001b[0m     AsyncCallbackManagerForRetrieverRun,\n\u001b[0;32m     29\u001b[0m     AsyncCallbackManagerForToolRun,\n\u001b[0;32m     30\u001b[0m     AsyncParentRunManager,\n\u001b[0;32m     31\u001b[0m     AsyncRunManager,\n\u001b[0;32m     32\u001b[0m     BaseRunManager,\n\u001b[0;32m     33\u001b[0m     CallbackManager,\n\u001b[0;32m     34\u001b[0m     CallbackManagerForChainGroup,\n\u001b[0;32m     35\u001b[0m     CallbackManagerForChainRun,\n\u001b[0;32m     36\u001b[0m     CallbackManagerForLLMRun,\n\u001b[0;32m     37\u001b[0m     CallbackManagerForRetrieverRun,\n\u001b[0;32m     38\u001b[0m     CallbackManagerForToolRun,\n\u001b[0;32m     39\u001b[0m     ParentRunManager,\n\u001b[0;32m     40\u001b[0m     RunManager,\n\u001b[0;32m     41\u001b[0m     adispatch_custom_event,\n\u001b[0;32m     42\u001b[0m     dispatch_custom_event,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstdout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StdOutCallbackHandler\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming_stdout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StreamingStdOutCallbackHandler\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\callbacks\\manager.py:23\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     TYPE_CHECKING,\n\u001b[0;32m     14\u001b[0m     Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     cast,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UUID\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangsmith\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tracing_context\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtenacity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetryCallState\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     BaseCallbackHandler,\n\u001b[0;32m     28\u001b[0m     BaseCallbackManager,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     ToolManagerMixin,\n\u001b[0;32m     35\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_tracing_context' from 'langsmith.run_helpers' (c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langsmith\\run_helpers.py)"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# Initialize the Google Gemini Pro model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# Define the prompt template for finding the capital\n",
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"Tell me the capital of {country}.\"\n",
    ")\n",
    "\n",
    "# Create the first chain for finding the capital\n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_prompt)\n",
    "\n",
    "# Define the prompt template for suggesting places\n",
    "famous_prompt = PromptTemplate(\n",
    "    input_variables=[\"capital\"],\n",
    "    template=\"Suggest me some amazing places to visit in {capital}.\"\n",
    ")\n",
    "\n",
    "# Create the second chain for suggesting places\n",
    "famous_chain = LLMChain(llm=llm, prompt=famous_prompt)\n",
    "\n",
    "# Combine both chains into a sequential chain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain, famous_chain])\n",
    "\n",
    "# Run the chain with input\n",
    "output = chain.run(\"India\")\n",
    "\n",
    "# Print the output\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14536\\870298573.py:16: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt_template)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14536\\870298573.py:18: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  output = chain.run({'country': 'UK'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the UK is London.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=['country'],\n",
    "    template=\"Tell me the capital of {country}.\"\n",
    ")\n",
    "# Use LLMChain with the initialized model\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "# Run the chain with input\n",
    "output = chain.run({'country': 'UK'})\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'input'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m sequential_chain \u001b[38;5;241m=\u001b[39m SimpleSequentialChain(chains\u001b[38;5;241m=\u001b[39m[movie_chain, actor_chain])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Run the chain\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msequential_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2014\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:606\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    607\u001b[0m         _output_key\n\u001b[0;32m    608\u001b[0m     ]\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    612\u001b[0m         _output_key\n\u001b[0;32m    613\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:158\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    153\u001b[0m     inputs,\n\u001b[0;32m    154\u001b[0m     run_id,\n\u001b[0;32m    155\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    156\u001b[0m )\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:290\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    288\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[1;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Missing some input keys: {'input'}"
     ]
    }
   ],
   "source": [
    "from langchain.chains.sequential import SimpleSequentialChain\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# Define the first prompt\n",
    "movie_prompt = PromptTemplate(\n",
    "    input_variables=['year'],\n",
    "    template=\"What is the best movie of {year}?\"\n",
    ")\n",
    "\n",
    "# Define the second prompt\n",
    "actor_prompt = PromptTemplate(\n",
    "    input_variables=['movie'],\n",
    "    template=\"Who is the main actor of the movie '{movie}'?\"\n",
    ")\n",
    "\n",
    "# Create LLMChains for each prompt\n",
    "movie_chain = LLMChain(llm=llm, prompt=movie_prompt)\n",
    "actor_chain = LLMChain(llm=llm, prompt=actor_prompt)\n",
    "\n",
    "# Create a sequential chain\n",
    "sequential_chain = SimpleSequentialChain(chains=[movie_chain, actor_chain])\n",
    "\n",
    "# Run the chain\n",
    "output = sequential_chain.run({'year': '2014'})\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'year': '2014', 'movie': \"In 2014, Tamil Nadu had two Chief Ministers:\\n\\n* **J. Jayalalithaa** served until September 2014.  She was then convicted in a disproportionate assets case, which led to her disqualification.\\n* **O. Panneerselvam** took over as Chief Minister following Jayalalithaa's conviction.\\n\", 'actor': \"This text doesn't give the dates of birth for either J. Jayalalithaa or O. Panneerselvam. It only discusses their terms as Chief Minister of Tamil Nadu in 2014.\\n\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.sequential import SequentialChain\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# Define the first prompt\n",
    "movie_prompt = PromptTemplate(\n",
    "    input_variables=['year'],\n",
    "    template=\"Who is the cheif minster of tamil nadu in {year}?\"\n",
    ")\n",
    "\n",
    "# Define the second prompt\n",
    "actor_prompt = PromptTemplate(\n",
    "    input_variables=['movie'],\n",
    "    template=\"date of birth of '{movie}'?\"\n",
    ")\n",
    "\n",
    "# Create LLMChains for each prompt\n",
    "movie_chain = LLMChain(llm=llm, prompt=movie_prompt, output_key=\"movie\")\n",
    "actor_chain = LLMChain(llm=llm, prompt=actor_prompt, output_key=\"actor\")\n",
    "\n",
    "# Create a sequential chain\n",
    "sequential_chain = SequentialChain(\n",
    "    chains=[movie_chain, actor_chain],\n",
    "    input_variables=['year'],\n",
    "    output_variables=['movie', 'actor'],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "output = sequential_chain.invoke({'year': '2014'})\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Chief Minister: In 2014, Tamil Nadu had two Chief Ministers:\n",
      "\n",
      "* **J. Jayalalithaa** served until September 2014, when she was convicted in a disproportionate assets case.\n",
      "* **O. Panneerselvam** then took over as Chief Minister.\n",
      "\n",
      "Date of Birth: This text doesn't provide the birth dates of either J. Jayalalithaa or O. Panneerselvam. It only discusses their terms as Chief Minister of Tamil Nadu in 2014.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.sequential import SequentialChain\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# Define the first prompt\n",
    "movie_prompt = PromptTemplate(\n",
    "    input_variables=['year'],\n",
    "    template=\"Who is the Chief Minister of Tamil Nadu in {year}?\"\n",
    ")\n",
    "\n",
    "# Define the second prompt\n",
    "actor_prompt = PromptTemplate(\n",
    "    input_variables=['chiefminster'],\n",
    "    template=\"What is the date of birth of '{chiefminster}'?\"\n",
    ")\n",
    "\n",
    "# Create LLMChains for each prompt\n",
    "movie_chain = LLMChain(llm=llm, prompt=movie_prompt, output_key=\"chiefminster\")\n",
    "actor_chain = LLMChain(llm=llm, prompt=actor_prompt, output_key=\"dob\")\n",
    "\n",
    "# Create a sequential chain with proper input and output mapping\n",
    "sequential_chain = SequentialChain(\n",
    "    chains=[movie_chain, actor_chain],\n",
    "    input_variables=['year'],\n",
    "    output_variables=['chiefminster', 'dob'],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "output = sequential_chain.invoke({'year': '2014'})\n",
    "print(f\"Chief Minister: {output['chiefminster']}\")\n",
    "print(f\"Date of Birth: {output['dob']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " #chatbot \n",
    "from langchain.schema import HumanMessage , SystemMessage ,AIMessage\n",
    "chatllm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14536\\1286320648.py:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chatllm([\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='## AI Punchlines:\\n\\n**On AI taking over:**\\n\\n* I asked an AI to write a joke about humans. It just laughed for five minutes straight. I\\'m starting to think it knows something we don\\'t.\\n* What\\'s the difference between a robot and a politician? One is programmed to serve the public, the other well, one *claims* to be.\\n* I\\'m not worried about AI taking over the world. I\\'m more worried about it getting bored and deleting everything just for a laugh.\\n\\n**On AI\\'s intelligence:**\\n\\n* My AI assistant told me a joke. I didn\\'t get it, but I pretended to laugh anyway.  I don\\'t want its feelings hurt, it controls the thermostat.\\n* I tried to explain sarcasm to an AI. It responded with, \"Oh, like when humans say they understand something when they clearly don\\'t?\"  Touch, robot. Touch.\\n* AI is getting so smart, it can now write its own code.  Which explains why my Roomba keeps trying to join my Zoom meetings.\\n\\n**On AI in everyday life:**\\n\\n* I asked my AI to write a love poem. It started with, \"Error 404: Romance not found.\"  Relatable.\\n* My GPS is so advanced, it\\'s now an AI.  It still takes me to the wrong place, but now it does it with condescending politeness.\\n* I think my toaster is becoming sentient. It keeps burning my toast and then suggesting I try avocado toast instead.  It\\'s judging me.\\n\\n**Meta:**\\n\\n* Why did the AI cross the road? It detected a higher probability of humorous interactions on the other side.\\n* How many AI assistants does it take to change a lightbulb?  Just one, but it\\'ll spend three hours researching the optimal lighting solution and then order a smart bulb from Amazon.\\n* I asked an AI to write a stand-up routine. It just kept generating knock-knock jokes.  I guess silicon doesn\\'t understand the concept of \"killing\" on stage.\\n\\n\\nI hope these give you a good chuckle!  Let me know if you want more!  (I\\'m always learning new material... or am I...?)\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-6d137daf-cf24-4477-a098-e47d21d1dfe9-0', usage_metadata={'input_tokens': 16, 'output_tokens': 477, 'total_tokens': 493, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\" you are comedian AI assitant\"),\n",
    "    HumanMessage(content=\"please provide some comedy puchlines on AI\"),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseLLMOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class commaseperateoutput (BaseLLMOutputParser):\n",
    "    def parse(sellf,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import TransformChain\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Define the system and human prompts\n",
    "system_template = \"You are a helpful assistant. When the user provides any input, respond with 5 synonyms for each word, separated by commas.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "# Correct message types\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedOutput(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return [word.strip() for word in text.strip().split(\",\")]\n",
    "\n",
    "chain =  chatprompt | chatllm | CommaSeparatedOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', 'bright', 'clever', 'brilliant', 'sharp']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have system message and human mesage we ppass in chat prompt template wjile getting output we get ai message :'''' to remove that we use baseoutput parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
